cols = everything(),
names_to = "variable",
values_to = "value"
)
ggplot(df_long, aes(x = variable, y = value)) +
geom_boxplot(outlier.alpha = 0.6) +
facet_wrap(~ variable, scales = "free_y") +
labs(
title = "Boxplots of Numeric Variables",
x = NULL,
y = NULL
) +
theme_minimal() +
theme(
axis.text.x = element_blank(),
axis.ticks.x = element_blank()
)
marketing_data_clean <- df_clean <- remove_outliers_iqr(marketing_data)
df_long_clean <- marketing_data_clean %>%
select(where(is.numeric)) %>%
pivot_longer(
cols = everything(),
names_to = "variable",
values_to = "value"
)
ggplot(df_long_clean, aes(x = variable, y = value)) +
geom_boxplot(outlier.alpha = 0.6) +
facet_wrap(~ variable, scales = "free_y") +
labs(
title = "Boxplots of Numeric Variables",
x = NULL,
y = NULL
) +
theme_minimal() +
theme(
axis.text.x = element_blank(),
axis.ticks.x = element_blank()
)
ggplot(df_long_clean, aes(x = variable, y = value)) +
geom_boxplot(outlier.alpha = 0.6) +
facet_wrap(~ variable, scales = "free_y") +
labs(
title = "Boxplots of Numeric Variables",
x = NULL,
y = NULL
) +
theme_minimal() +
theme(
axis.text.x = element_blank(),
axis.ticks.x = element_blank()
)
marketing_data <- marketing_data %>%
select(-Income_missing, -row_index,
-Age_missing, -CampaignChannel_missing,
-CampaignType_missing, -ClickThroughRate_missing,
-Conversion_missing, -ConversionRate_missing,
-CustomerID_missing, -EmailClicks_missing,
-EmailOpens_missing, -LoyaltyPoints_missing,
-PagesPerVisit_missing, -PreviousPurchases_missing,
-row_index_missing, -SocialShares_missing, -TimeOnSite_missing,
-WebsiteVisits_missing, -AdSpend_missing)
df_long <- marketing_data %>%
select(where(is.numeric)) %>%
pivot_longer(
cols = everything(),
names_to = "variable",
values_to = "value"
)
#-----------------------------------
# Load necessary libraries and files
#-----------------------------------
library(dplyr)
library(ggplot2)
library(tidyr)
source("utils_preprocessing.R")
#----------------
# Read data
#----------------
marketing_data <- read.csv(file.path(getwd(), "marketing.csv"), header = TRUE, sep = ",")
#------------------------
# Add a row number column
#------------------------
marketing_data <- marketing_data %>%
mutate(row_index = row_number())
#---------------------------------
# Display rows with missing values
#---------------------------------
marketing_data %>%
filter(if_any(everything(), ~ is.na(.) | . == "NA"))
#--------------------------------------------------------
# Perform conditional median imputation on missing values
# Condition: Gender of the customer
#--------------------------------------------------------
marketing_data <- df_imputed <- impute_by_group_median(
data = marketing_data,
group_col = "Gender"
)
marketing_data <- marketing_data %>%
select(-Income_missing, -row_index,
-Age_missing, -CampaignChannel_missing,
-CampaignType_missing, -ClickThroughRate_missing,
-Conversion_missing, -ConversionRate_missing,
-CustomerID_missing, -EmailClicks_missing,
-EmailOpens_missing, -LoyaltyPoints_missing,
-PagesPerVisit_missing, -PreviousPurchases_missing,
-row_index_missing, -SocialShares_missing, -TimeOnSite_missing,
-WebsiteVisits_missing, -AdSpend_missing)
df_long <- marketing_data %>%
select(where(is.numeric)) %>%
pivot_longer(
cols = everything(),
names_to = "variable",
values_to = "value"
)
ggplot(df_long, aes(x = variable, y = value)) +
geom_boxplot(outlier.alpha = 0.6) +
facet_wrap(~ variable, scales = "free_y") +
labs(
title = "Boxplots of Numeric Variables",
x = NULL,
y = NULL
) +
theme_minimal() +
theme(
axis.text.x = element_blank(),
axis.ticks.x = element_blank()
)
marketing_data_clean <- df_clean <- remove_outliers_iqr(marketing_data)
df_long_clean <- marketing_data_clean %>%
select(where(is.numeric)) %>%
pivot_longer(
cols = everything(),
names_to = "variable",
values_to = "value"
)
ggplot(df_long_clean, aes(x = variable, y = value)) +
geom_boxplot(outlier.alpha = 0.6) +
facet_wrap(~ variable, scales = "free_y") +
labs(
title = "Boxplots of Numeric Variables",
x = NULL,
y = NULL
) +
theme_minimal() +
theme(
axis.text.x = element_blank(),
axis.ticks.x = element_blank()
)
library(dplyr)
library(ggplot2)
library(tidyr)
library(caret)
source("utils_preprocessing.R")
marketing_data <- read.csv(file.path(getwd(), "marketing.csv"), header = TRUE, sep = ",")
split <- split_data(marketing_data, target="Conversion", prop=0.8, stratify = TRUE, seed = 123)
train_data <- split$train
test_data <- split$test
outlier_handler <- fit_outlier_handler(train_data)
install.packages("glmnet")
library(glmnet)
library(dplyr)
library(ggplot2)
library(tidyr)
library(glmnet)
library(caret)
source("utils_preprocessing.R")
marketing_data <- read.csv(file.path(getwd(), "marketing.csv"), header = TRUE, sep = ",")
split <- split_data(marketing_data, target="Conversion", prop=0.8, stratify = TRUE, seed = 123)
train_data <- split$train
test_data <- split$test
X_train <- train_data %>%
select(-Conversion)
y_train <- as.factor(train_data$Conversion)
X_test <- test_data %>%
select(-Conversion)
y_test <- as.factor(test_data$Conversion)
outlier_handler <- fit_outlier_handler(X_train)
X_train <- apply_outlier_handler(X_train, outlier_handler)
X_test <- apply_outlier_handler(X_test, outlier_handler)
imputer <- fit_imputer(X_train)
imputer <- fit_imputer(X_train)
library(dplyr)
library(ggplot2)
library(tidyr)
library(glmnet)
library(caret)
source("utils_preprocessing.R")
marketing_data <- read.csv(file.path(getwd(), "marketing.csv"), header = TRUE, sep = ",")
split <- split_data(marketing_data, target="Conversion", prop=0.8, stratify = TRUE, seed = 123)
train_data <- split$train
test_data <- split$test
X_train <- train_data %>%
select(-Conversion)
y_train <- as.factor(train_data$Conversion)
X_test <- test_data %>%
select(-Conversion)
y_test <- as.factor(test_data$Conversion)
outlier_handler <- fit_outlier_handler(X_train)
X_train <- apply_outlier_handler(X_train, outlier_handler)
X_test <- apply_outlier_handler(X_test, outlier_handler)
imputer <- fit_imputer(X_train)
X_train <- apply_imputer(X_train, imputer)
X_test <- apply_imputer(X_test, imputer)
encoder <- fit_encoder(X_train)
X_train <- apply_encoder(X_train, encoder)
library(dplyr)
library(ggplot2)
library(tidyr)
library(glmnet)
library(caret)
source("utils_preprocessing.R")
marketing_data <- read.csv(file.path(getwd(), "marketing.csv"), header = TRUE, sep = ",")
split <- split_data(marketing_data, target="Conversion", prop=0.8, stratify = TRUE, seed = 123)
train_data <- split$train
test_data <- split$test
X_train <- train_data %>%
select(-Conversion)
y_train <- as.factor(train_data$Conversion)
X_test <- test_data %>%
select(-Conversion)
y_test <- as.factor(test_data$Conversion)
outlier_handler <- fit_outlier_handler(X_train)
X_train <- apply_outlier_handler(X_train, outlier_handler)
X_test <- apply_outlier_handler(X_test, outlier_handler)
imputer <- fit_imputer(X_train)
X_train <- apply_imputer(X_train, imputer)
X_test <- apply_imputer(X_test, imputer)
encoder <- fit_encoder(X_train)
X_train <- apply_encoder(X_train, encoder)
X_test <- apply_encoder(X_test, encoder)
zv_filter <- fit_zv_filter(X_train)
X_train <- apply_zv_filter(X_train, zv_filter)
X_test <- apply_zv_filter(X_test, zv_filter)
scaler <- fit_scaler(X_train)
X_train <- apply_scaler(X_train, scaler)
X_test <- apply_scaler(X_test, scaler)
# Convert once
X_train <- as.matrix(X_train)
X_test  <- as.matrix(X_test)
class_weights <- compute_class_weights(y_train)
obs_weights <- class_weights[as.character(y_train)]
alpha_grid <- seq(0, 1, by = 0.1)
set.seed(123)
cv_models <- lapply(alpha_grid, function(a) {
cv.glmnet(
x = X_train,
y = y_train,
family = "binomial",
alpha = a,
weights = obs_weights,
standardize = FALSE,
type.measure = "deviance"
)
})
# --- Select best alpha ---
cv_errors <- sapply(cv_models, function(m) min(m$cvm))
best_idx <- which.min(cv_errors)
best_alpha  <- alpha_grid[best_idx]
best_lambda <- cv_models[[best_idx]]$lambda.min
# --- Final model ---
final_model <- glmnet(
x = X_train,
y = y_train,
family = "binomial",
alpha = best_alpha,
lambda = best_lambda,
weights = obs_weights,
standardize = FALSE
)
# --- Predictions ---
prob_test <- predict(final_model, X_test, type = "response")
pred_test <- ifelse(
prob_test > 0.5,
levels(y_train)[2],
levels(y_train)[1]
)
pred_test <- factor(pred_test, levels = levels(y_train))
# --- caret confusion matrix ---
cm <- confusionMatrix(
data = pred_test,
reference = y_test,
positive = levels(y_train)[2]
)
print(cm)
#-----------------------------------
# Load libraries and preprocessing
#-----------------------------------
library(dplyr)
library(glmnet)
library(caret)
source("utils_preprocessing.R")
#----------------
# Read data
#----------------
marketing_data <- read.csv("marketing.csv")
#----------------------------
# Split data
#----------------------------
split <- split_data(
marketing_data,
target = "Conversion",
prop = 0.8,
stratify = TRUE,
seed = 123
)
train_data <- split$train
test_data  <- split$test
X_train <- train_data %>% select(-Conversion)
y_train <- as.factor(train_data$Conversion)
X_test  <- test_data %>% select(-Conversion)
y_test  <- as.factor(test_data$Conversion)
#------------------------
# Preprocessing (fit on train, apply to both)
#------------------------
outlier_handler <- fit_outlier_handler(X_train)
X_train <- apply_outlier_handler(X_train, outlier_handler)
X_test  <- apply_outlier_handler(X_test,  outlier_handler)
imputer <- fit_imputer(X_train)
X_train <- apply_imputer(X_train, imputer)
X_test  <- apply_imputer(X_test,  imputer)
encoder <- fit_encoder(X_train)
X_train <- apply_encoder(X_train, encoder)
X_test  <- apply_encoder(X_test,  encoder)
zv_filter <- fit_zv_filter(X_train)
X_train <- apply_zv_filter(X_train, zv_filter)
X_test  <- apply_zv_filter(X_test,  zv_filter)
scaler <- fit_scaler(X_train)
X_train <- apply_scaler(X_train, scaler)
X_test  <- apply_scaler(X_test,  scaler)
X_train <- as.matrix(X_train)
X_test  <- as.matrix(X_test)
#-----------------------------
# Class weights
#-----------------------------
class_weights <- compute_class_weights(y_train)
obs_weights   <- class_weights[as.character(y_train)]
#-----------------------------------
# Elastic-net CV (alpha + lambda)
#-----------------------------------
alpha_grid <- seq(0, 1, by = 0.1)
set.seed(123)
cv_models <- lapply(alpha_grid, function(a) {
cv.glmnet(
x = X_train,
y = y_train,
family = "binomial",
alpha = a,
weights = obs_weights,
standardize = FALSE
)
})
cv_errors <- sapply(cv_models, function(m) min(m$cvm))
best_idx  <- which.min(cv_errors)
best_alpha  <- alpha_grid[best_idx]
best_lambda <- cv_models[[best_idx]]$lambda.min
best_cv     <- cv_models[[best_idx]]
#-----------------------------------
# ðŸ”¥ Threshold tuning (HERE)
#-----------------------------------
# Out-of-fold probabilities
eta <- best_cv$fit.preval %*%
best_cv$glmnet.fit$beta[, best_cv$lambda == best_lambda] +
best_cv$glmnet.fit$a0[best_cv$lambda == best_lambda]
cv_probs <- as.numeric(1 / (1 + exp(-eta)))
tune_threshold <- function(probs, y, grid = seq(0.05, 0.95, by = 0.01)) {
scores <- sapply(grid, function(t) {
preds <- factor(ifelse(probs > t, "1", "0"), levels = levels(y))
confusionMatrix(preds, y, positive = "1")$byClass["Balanced Accuracy"]
})
grid[which.max(scores)]
}
best_threshold <- tune_threshold(cv_probs, y_train)
#-----------------------------------
# Final model
#-----------------------------------
final_model <- glmnet(
x = X_train,
y = y_train,
family = "binomial",
alpha = best_alpha,
lambda = best_lambda,
weights = obs_weights,
standardize = FALSE
)
#-----------------------------------
# Test evaluation (ONLY here)
#-----------------------------------
prob_test <- predict(final_model, X_test, type = "response")
pred_test <- factor(
ifelse(prob_test > best_threshold, "1", "0"),
levels = levels(y_train)
)
cm <- confusionMatrix(
pred_test,
y_test,
positive = "1"
)
print(cm)
#-----------------------------------
# Load libraries and preprocessing
#-----------------------------------
library(dplyr)
library(glmnet)
library(caret)
source("utils_preprocessing.R")
#----------------
# Read data
#----------------
marketing_data <- read.csv("marketing.csv")
#----------------------------
# Split data
#----------------------------
split <- split_data(
marketing_data,
target = "Conversion",
prop = 0.8,
stratify = TRUE,
seed = 123
)
train_data <- split$train
test_data  <- split$test
X_train <- train_data %>% select(-Conversion)
y_train <- as.factor(train_data$Conversion)
X_test  <- test_data %>% select(-Conversion)
y_test  <- as.factor(test_data$Conversion)
#------------------------
# Preprocessing (fit on train, apply to both)
#------------------------
outlier_handler <- fit_outlier_handler(X_train)
X_train <- apply_outlier_handler(X_train, outlier_handler)
X_test  <- apply_outlier_handler(X_test,  outlier_handler)
imputer <- fit_imputer(X_train)
X_train <- apply_imputer(X_train, imputer)
X_test  <- apply_imputer(X_test,  imputer)
encoder <- fit_encoder(X_train)
X_train <- apply_encoder(X_train, encoder)
X_test  <- apply_encoder(X_test,  encoder)
zv_filter <- fit_zv_filter(X_train)
X_train <- apply_zv_filter(X_train, zv_filter)
X_test  <- apply_zv_filter(X_test,  zv_filter)
scaler <- fit_scaler(X_train)
X_train <- apply_scaler(X_train, scaler)
X_test  <- apply_scaler(X_test,  scaler)
X_train <- as.matrix(X_train)
X_test  <- as.matrix(X_test)
#-----------------------------
# Class weights
#-----------------------------
class_weights <- compute_class_weights(y_train)
obs_weights   <- class_weights[as.character(y_train)]
#-----------------------------------
# Elastic-net CV (alpha + lambda)
#-----------------------------------
alpha_grid <- seq(0, 1, by = 0.1)
set.seed(123)
cv_models <- lapply(alpha_grid, function(a) {
cv.glmnet(
x = X_train,
y = y_train,
family = "binomial",
alpha = a,
weights = obs_weights,
standardize = FALSE,
keep = TRUE
)
})
cv_errors <- sapply(cv_models, function(m) min(m$cvm))
best_idx  <- which.min(cv_errors)
best_alpha  <- alpha_grid[best_idx]
best_lambda <- cv_models[[best_idx]]$lambda.min
best_cv <- cv_models[[best_idx]]
lambda_idx <- which(best_cv$lambda == best_lambda)
cv_probs <- best_cv$fit.preval[, lambda_idx]
cv_probs <- as.numeric(cv_probs)
#-----------------------------------
# ðŸ”¥ Threshold tuning (HERE)
#-----------------------------------
tune_threshold <- function(probs, y, grid = seq(0.05, 0.95, by = 0.01)) {
scores <- sapply(grid, function(t) {
preds <- factor(ifelse(probs > t, "1", "0"), levels = levels(y))
confusionMatrix(preds, y, positive = "1")$byClass["Balanced Accuracy"]
})
grid[which.max(scores)]
}
best_threshold <- tune_threshold(cv_probs, y_train)
#-----------------------------------
# Final model
#-----------------------------------
final_model <- glmnet(
x = X_train,
y = y_train,
family = "binomial",
alpha = best_alpha,
lambda = best_lambda,
weights = obs_weights,
standardize = FALSE
)
#-----------------------------------
# Test evaluation (ONLY here)
#-----------------------------------
prob_test <- predict(final_model, X_test, type = "response")
pred_test <- factor(
ifelse(prob_test > best_threshold, "1", "0"),
levels = levels(y_train)
)
cm <- confusionMatrix(
pred_test,
y_test,
positive = "1"
)
print(cm)
print(best_threshold)
